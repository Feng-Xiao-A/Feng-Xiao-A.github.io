[{"title":"README","url":"/2022/04/26/README/","content":"\n打工是不可能打工的，这辈子都不可能打工的 打工是不可能打工的，这辈子都不可能打工的 打工是不可能打工的，这辈子都不可能打工的\n\n\nREADME\n","categories":["README"],"tags":["README"]},{"title":"第三章：概率密度函数的估计","url":"/2022/04/28/Pattern%20Recognition/%E4%B8%89%EF%BC%8C%E6%A6%82%E7%8E%87%E5%AF%86%E5%BA%A6%E5%87%BD%E6%95%B0%E7%9A%84%E4%BC%B0%E8%AE%A1/%E6%A6%82%E7%8E%87%E5%AF%86%E5%BA%A6%E5%87%BD%E6%95%B0%E7%9A%84%E4%BC%B0%E8%AE%A1/","content":"\nThe project will be configured before the first of June\n\n\n概率密度函数的估计\n1. 引言\n\n基于样本的两步贝叶斯决策：先通过训练样本估计概率密度函数，再通过统计决策进行类别判定。\n参数估计：最大似然估计；贝叶斯估计。\n非参数估计：直方图法，近邻法，Parzen窗法。\n统计量：针对不同要求构造出样本的某种函数，这种函数在统计学中称为统计量。\n参数空间：总体分布未知参数的全部可容许值组成的集合。\n点估计，估计量，估计值： 点估计构造一个统计量  作为参数  的估计 ，  称为  的估计量。如果  是属于类别  的几个样本观察值，代人统计量  就得到对于第  类的  的具体数值，这个数值称为  的估计值。\n区间估计：要求用区间  作为  可能取值范围的一种估计，这个区间称为置信区间。\n无偏性、有效性：对于多次估计来说，估计量能以较小的方差平均地表示其真实值，并不能保证具体的一次估计的性能。\n一致性：保证当样本数无穷多时，每一次的估计量都将在概率意义上任意地接近其真实值。\n\n2. 最大似然估计\n假设：样本独立同分布采样得到且概率分布函数形式已知。\n参数  相对于样本集  的似然函数：  最大似然估计量  对数似然函数  当  有梯度算子  对梯度求导并令其等于零  即  得到  个方程,方程组的解就是对数似然函数的极值点。有时上述方程组会有多个解，其中使得似然函数最大的那个解才是最大似然估计量。此外，并不是所有的概率密度形式都可以用上面的方法求得最大似然估计。\n正态分布下的最大似然估计\n单变量正态分布:\n 要估计的参数 ，用于估计的样本  。  分别对两个末知参数求偏导：  最大似然估计是以下方程组的解：  解得：  对于多元正态分布,均值和方差的最大似然估计是：  最大似然估计量是平方误差一致估计量,不一定是无偏估计量。上例中  是无偏的,而  的无偏估计为： \n3. 贝叶斯估计与贝叶斯学习\n3.1 贝叶斯估计：\n把待估计的参数本身也看作随机变量，除了观测数据外, 还可以考虑参数的先验分布。 设样本的取值空间是  ，参数的取值空间是 ,那么，当用  来作为估计时总期望风险就是  在有限样本集合  的情况下,对所有的样本求条件风险最小,即  定义损失函数常用平方误差:  此时有在样本  条件下  在给定样本集  条件下  最小平方误差损失函数下，贝叶斯估计步骤 (1) 根据对问题的认识或者猜测确定  的先验分布密度  。 (2) 由于样本是独立同分布的, 而且已知样本密度函数的形式 , 可以形式上求出样本集的联合分布为  (3) 利用贝叶斯公式求  的后验概率分布  (4)  的贝叶斯估计量  共轭：  为正态分布时,  也为正态分布。 也可由后验概率分布直接得到样本的概率密度函数：  如果完全没有先验知识, 即认为  为均匀分布,则  完全取决于  。如果先验知识非常强 ，除非  的似然函数为0，否则最后的估计就是，样本不再起作用。\n3.2 贝叶斯学习：\n贝叶斯学习则把贝叶斯估计的原理用于直接从数据对概率密度函数进行迭代估计。\n样本集，贝叶斯估计量：  其中：  当  时, 有  可得递推公式：  先验概率记作 , 表示在没有样本情況下的概率密度估计。根据上式, 随着样本数的增加, 可以得到一系列对概率密度函数参数的估计  称作递推的贝叶斯估计。如果随着样本数的增加, 后验概率序列逐渐尖锐, 逐步趋向于以  的真实值为中心的一个尖峰, 当样本无穷多时收敛于在参数真实值上的脉冲函数, 则这一过程称作贝叶斯学习。此时，估计的样本概率密度函数也逼近真实的密度函数 \n3.3 正态分布的贝叶斯估计：\n一维正态分布模型，假设均值  是待估计的参数, 方差  已知，分布密度为：  假定均值  的先验分布是正态分布，其均值为 , 方差为  ，即  对均值  进行估计：  分子部分：  即：  可见  也是一个正态分布, 可得  其中的参数满足  整理后得  其中,  ; 贝叶斯估计值：  也可由后验分布直接求出样本的密度函数  贝叶斯估计不但使用样本中提供的信息进行估计，还能把待估计参数的先验知识融合进来，并且能够根据数据量大小和先验知识的确定程度来调和两部分信息的相对贡献。\n4. 概率密度估计的非参数方法\n对样本的分布并没有充分的了解，难以给出密度函数形式的情况下，需要非参数估计。即不对概率密度函数的形式作任何假设，而是直接用样本估计出整个函数。这种估计只能是用数值方法取得，无法得到完美的封闭函数形式。从另外的角度来看，概率密度函数的参数估计实际是在指定的一类函数中选择一个函数作为对末知函数的估计，而非参数估计则可以看作是从所有可能的函数中进行的一种选择。\n4.1 直方图法\n\n把 维向量样本  的每个分量在其取值范围内分成  个等间隔的小窗。则会得到  个小舱，每个小舱的体积记作  。\n统计落人每个小舱内的样本数目  。\n把每个小舱内的概率密度看作是常数，并用  作为其估计值,  为样本总数。\n\n\n\n\n基本原理 : 样本集  是从服从密度函数  的总体中独立抽取出来的，求  的估计  。与参数估计时一样，这里不考虑类别，即假设样本都是来自同一个类别，对不同类别只需要分别进行估计即可。考虑在样本所在空间的某个小区域 ，某个随机向量落入这个小区域的概率是：  当小区域中实际落人了  个样本时，  的一个很好的估计是  当  连续、且小区域  的体积  足够小时，可以假定在该小区域范围内  是常数，则  可得, 在小区域  的范围内, 概率密度的估计。  小舱的选择应该与样本总数相适应。理论上,假定样本总数是 , 小舱的体积 为 , 在  附近位置上落人小 舱的样本个数是 , 那么当样本趋于无穷多时  收敛于  的条件是： (1)  (2)  (3) \n在有限数目的样本下, 如果所有小舱的体积相同, 那么就有可能在样本密度大的地方一个小舱里有很多样本, 而在密度小的地方则可能一个小舱里只有很少甚至没有样本，这样就可能导致密度的估计在样本密度不同的地方表现不一致。因此, 要想得到更好的估计，需要采用能够根据样本分布情况调整小舱体积的方法。\n4.2 Kn 近邻法 :\n根据总样本确定一个参数  。在求  处的密度估计  时, 调整小舱体积, 直到小舱恰好落入  个样本  为了取得好的估计效果,需要根据条件来选择  与  的关系,比如可以选取为 ， 为某个常数  近邻法在  的取值范围内以每一点为小舱中心用上式进行估计，而非把  的取值范围划分为若干个区域。\n\n\n\n4.3 Parzen 窗法 :\n固定小舱体积的情况下，像  近邻法用滑动的小舱来估计每个点上的概率密度，而不是像直方图中那样仅在每个小舱内估计平均密度。 假设  是  维特征向量, 并假设每个小舱是一个超立方体, 它在每一维的棱长都为 , 则小舱的体积是：  定义维单位方窗函数： 若其他 共有  个观测样本 , 则落入以  为中心的超立方体内的样本数为：  对于任意一点  的密度估计的表达式：  定义核函数（也称窗函数）：  它反映了一个观测样本  对在  处的概率密度估计的贡献, 与样本  与  的距离有关, 可记作  。概率密度估计就是在每一点上把所有观测样本的贡献进行平均  核函数本身满足密度函数的要求，则估计函数满足密度函数的要求，即函数值非负且积分为 1 。 且 以上定义的立方体核函数满足这一条件。 Parzen 窗估计也可以看作是用核函数对样本在取值空间中进行揷值。多种核函数：\n\n方窗\n\n若其他 其中, 为超立方体的棱长。\n\n高斯窗（正态窗）\n\n 即以样本  为均值、协方差矩阵为  的正态分布函数。一维情况下则为 \n\n超球窗\n\n若其他 其中  是超球体的体积,  是超球体半径。 这些窗函数都有一个表示窗口宽度的参数(平滑参数）, 反映了一个样本对多大范围内的密度估计产生影响。当被估计的密度函数连续时，在核函数及其参数满足一定的条件下，Parzen 窗估计是渐近无偏和平方误差一致的。这些条件主要是: 对称且满足密度函数条件、有界、核函数取值随着距离的减小而迅速减小、对应小舱的体积随着样本数的增加而趋于零，但需慢于  趋于零的速度。以下为两种不同分布情况下用不同参数和高斯窗进行估计的结果，其中，为可调节的参量。\n\n\n\n作为非参数方法的共同问题是对样本数目需求较大，只要样本数目足够大，总可以保证收敛于任何复杂的未知密度，但是计算量和存储量都比较大。当样本数很少时，如果能够对密度函数有先验认识，则参数估计方法能取得更好的估计效果。\n","categories":["模式识别"],"tags":["模式识别"]},{"title":"第二章：统计决策方法","url":"/2022/04/28/Pattern%20Recognition/%E4%BA%8C%EF%BC%8C%E7%BB%9F%E8%AE%A1%E5%86%B3%E7%AD%96%E6%96%B9%E6%B3%95/%E7%BB%9F%E8%AE%A1%E5%86%B3%E7%AD%96%E6%96%B9%E6%B3%95/","content":"\nThe project will be configured before the first of June\n\n\n统计决策方法\n1. 贝叶斯决策\n在类条件概率密度和先验概率已知或可以估计的情况下，通过贝叶斯公式比较样本属于两类的后验概率，将类别决策为后验概率大的一类，这样做的目的是使总体错误率最小。  两类问题，错误率定义为所有服从同样分布的独立样本上错误概率的期望,正确率 如果决策如果决策\n2. 最小错误率贝叶斯决策\n2.1 两类最小错误率贝叶斯决策：\n则\n后验概率可由贝叶斯公式求得  引入似然比阀值， 则 引入对数似然比 则\n2.2 决策线\n\n\n\n2.3 错误率\n 第一类样本决策为第二类的错误率：  第二类样本决策为第一类的错误率： \n2.4 多类情况下，决策规则\n若则\n错误率： \n3. 最小风险贝叶斯决策\n考虑各种错误造成损失不同时的一种最优决策。\n\n\n\n采取决策的期望损失  最小化期望风险  决策 则 在实际是两类且决策也是两类时，决策为 则 引入似然比 ，则\n4. 两类错误率，Neyman-Pearson决策与ROC曲线\n4.1 混淆矩阵\n\n\n\n灵敏度：\n特异度：\n假阳性/第一类错误率  \n假阴性/第二类错误率  \n4.2 Neyman-Pearson决策\n固定一类错误率，使另一类错误率尽可能小  Lagrange乘子法  有  分别对和决策边界求导得必要条件  考虑到  ，有决策规则 则  常通过数值方法求得，通过到的映射关系，由， 求得 ，并调节  大小得到合适的错误率。 \n4.3 ROC 曲线\n通过设定不同的阀值画出单独用一个特征作为指标划分两类时的ROC曲线\n4.4 AUC\n计算AUC并通过比较不同特征间的AUC来得知哪个特征包含更多的分类信息。此外，从整体上看AUC越接近1.0，方法的性能越好。\n\n\n\n利用有限个测试样例绘图：给定 个正例和 个反例，根据学习器预测结果对样例进行排序，先把分类阈值设为最大，此时真正例率和假正例率均为 0，在坐标  处标记一个点，然后调节分类阈值依次将排序的每个样例划分为正例。设前一个标记点坐标为 ， 划分个样例后新增真正样例，假正样例，则对应标记点的 坐标为 ，并用线段连接相邻点，则  可估算为 \n5. 正态分布下的统计决策\n5.1 多元正态分布\n 期望   边缘分布   协方差矩阵总是对称非负定阵，现仅考虑为正定阵的情况。 \n5,2 多元正态分布的性质\n\n参数 和对分布的决定性\n\n\n\n\n\n等密度点的轨迹为一超椭球面 主轴方向由的本征向量所决定，主轴的长度与的本征值成正比。区域中心由确定，大小由确定。等密度点轨迹是由 到的 Mahalanobis 距离为常数的超椭球面。其大小是样本对于均值向量的离散度度量。\n\n\n\n不相关性等价于独立性 如果多元正态随机向量的协方差阵是对角阵，则的分量是相互独立的正态分布随机变量。\n边缘分布和条件分布的正态性 多元正态分布的边缘分布和条件分布仍然是正态分布。\n线性变换的正态性\n\n 由于为对称阵，则总可以找到非奇异阵使得各随机变量在新的坐标系中是独立的\n\n线性组合的正态性\n\n\n5.3 正态分布概率模型下的最小错误率贝叶斯决策\n多元正态概率型下，判别函数为  决策面方程 \n\n一， 时：每类的协⽅差矩阵都相等,⽽且类内各特征间相互独⽴，具有相等的⽅差\n\n，从几何上看,相当于各类样本落人以  为中心的同样大小的一些超球体内，决策方程  判别函数为线性函数，决策面是由线性方程  所确定的一个超平面(如果决策域  与  相毗邻)  其中： \n ，超平面通过  与  连线中点并与连线正交。当  不相等时，决策面与先验概率相等时的决策面平行，只是向先验概率小的方向偏移，即先验概率大的一类要占据更大的决策空间。\n\n\n\n\n决策面  此时决策规则为最小距离分类器 则 二， 时：\n\n，几何上各类样本集中于以该类均值  点为中心的同样大小和形状的超椭球内。 判别式  其中  决策面仍是一个超平面，如果决策域  和  毗邻，则决策面方程应满足 即  其中 \n，决策规则为计算出  到每类的均值点  的 Mahalanobis 距离平方 ，最后把  归于  最小的类别  此时决策面通过  与  连线的中点 。若先验概率不相等，  则在  与  连线上向先验概率小的均值点偏移。判别式的正向方向为指向的方向，判别式大于零则归类到所指向的的类别。\n\n三， 时：\n判别式  其中 矩阵维列向量 这时判别函数式将  表示为  的二次型。如果决策域  和  毗邻，则决策面方程即  决策面为超二次曲面，随着  的不同而呈现为某种超二次曲面，即超球面、超椭球面、超抛物面、超双曲面或超平面。\n6. 错误率的计算\n最小错误率贝叶斯决策的错误率是  类条件概率密度函数解析表达式较复杂时，计算错误率过于复杂。在处理实际问题时对错误率的计算或估计的方法可概括为： (1) 按理论公式计算； (2) 计算错误率上界 ; (3) 实验估计。\n6.1 正态分布下错误率的计算\n最小错误率贝叶斯决策规则的负对数似然比形式: \n决策面是的二次型，当各协方差阵相等时，决策面就变成的线性函数,其决策规则简化为：  易知服从一维正态分布，对于 ，可计算出决定一维正态分布的参数均值  及方差  :  同样对于  :  错误率计算 其中\n\n\n\n6.2 高维独立随机变量错误率估计\n当维随机向量的分量间相互独立时:  负对数似然比   其中  根据独立性假设和中心极限定理，  较大时无论  密度函数如何，  的密度函数总是趋于正态分布，由此可得  的均值  及方差  ：  由于  和  都是一维随机变量  的函数，在大多数情况下，计算这些参数相对比较容易，即使非正态情况亦是如此，所以可以把  近似看成是服从  的一维正态分布的随机变量，再由近似算出错误率。\n6.3 离散概率模型下的统计决策\n一阶马尔可夫链：第  时刻上的取值仅依赖于第  时刻的取值  转移概率  对一个长度为  的序列，我们观察到这个序列的概率是  DNA 序列每一位置有四种状态,转移概率就是一个  的矩阵,称作状态转移矩阵。\n\n\n\n岛的识别中岛记作 “  \"，非岛一类记作\"\"，马尔可夫转移概率分别记作 ，。计算通常采用对数似然比 \n\n\n\n两类的转移概率密度可由下式估计 和\n阈值选取： 阚值的选取可以根据先验概率，也可以根据最小风险的原则确定，或者根据对两类错误率的特殊要求决定。如果两类的先验概率相同且两类错误的损失相同，则对数似然比决策的阈值就是0。在这里，由于概率模型是用数值方法估计的，很难从理论上计算错误率。\n\n\n\n在实际应用中，常把训练数据代到中，统计所有训练样本的似然比取值的分布。选用不同的阈值来做决策就会导致不同的错误情况，可从直方图上确定满意的阈值，或者通过变动不同阈值画出ROC曲线来决定阈值选择。此外，以上没有考虑起始和终止状态的问题。一般情况下起始和结束的概率就可以用基因组上出现各个核苷酸的概率来代替。如果在某些场景下需要更精确地控制片段的起始和结束，那么用同样的方法可以估计起始和终止的转移概率。\n6.4 隐马尔可夫模型\n\n\n\n对前  个位置，  表示当第  位置对应隐状态为  时能得到的最大概率。  递归形式:  最大似然路径 可通过回溯的方法求得，  并且  这种做法叫Viterbi算法\n教材扩展：\n待补充。。。。。。\n本章概要：先验概率/后验概率/类条件密度，马尔可夫模型\n","categories":["模式识别"],"tags":["模式识别"]},{"title":"第一章：概论","url":"/2022/04/28/Pattern%20Recognition/%E4%B8%80%EF%BC%8C%E6%A6%82%E8%AE%BA/%E6%A6%82%E8%AE%BA/","content":"\nThe project will be configured before the first of June\n\n\n概论:\n1. 模式与模式识别\n通过以往对特定事物的认知来识别目标中的特定事物，例如从心电图中各波的形状判断病人的健康情况。\n2. 模式识别的主要方法\n\n基于知识的方法：根据样本特征与类别间关系的认知建立推理系统，对未知样本类别决策。\n基于数据的方法：依据训练样本建立不完全确定内部机理的表示与关系的系统，对未知样本类别决策。\n\n3. 监督模式识别与非监督模式识别\n\n监督模式识别：利用了有标签的训练样本。\n非监督模式识别：没有利用有标签的训练样本，对训练样本采用不同的划分方法可能导致不同的结果。\n\n4. 模式识别系统举例\n\n语音识别：对一系列连续的音素进行分类，需考虑音素之间的相互影响。例如利用多阶隐马尔可夫模型。\n说人话识别：与语言识别基本原理相同，只是分类目标由语音变成了说话人。\n字符与文字识别：OCR（detection-classification）等。单字识别是OCR的基础，将图片向多方向投影得到像素密度即数量特征；根据对汉字结构的认知提取有效特征点并编码成数字特征。特征提取后每个字就是一个特征向量代表的样本，接下来涉及到多分类问题。分类器设定通常需要结合对文字结构的认知（旋转和尺度不变性）。\n复杂图像中特定目标的识别：目标检测方法判断每个子图像是汽车还是背景，检测出汽车后可追踪其在连续图像中的运动轨迹来识别是否有违章行为等；可根据汽车图像识别出车牌位置再利用数字识别识别车牌号等；路人检测再进行人脸识别，行为识别等。\n根据地震勘探数据对地下储层性质的识别：在探井处利用地震信号提取特征并结合地下储层性质类别建立分类器；探井数不足以用来训练时可利用非监督学习方法对地震勘测信号聚类划分，由地质学家分析划分来实现对储层性质的识别。\n利用基因表达数据进行癌症的分类：利用基因表达作为病例特征研究病例之间的分类和聚类；利用病例表达作为基因特征研究基因之间的分类和聚类等。\n\n5. 模式识别系统的典型构成\n\n处理监督模式识别的一般步骤 分析问题，原始特征提取，特征提取与选择，分类器设计，分类决策；\n处理非监督模式识别的一般步骤 分析问题，原始特征提取，特征提取与选择，聚类分析，结果解释；\n\n本章概要：模式，样本，样本集，类或类别，特征，已知样本，未知样本。\n\n","categories":["模式识别"],"tags":["模式识别"]},{"title":"Test","url":"/2022/04/26/Test/","content":"主要内容\n\nMarkdown是什么？\n谁创造了它？\n为什么要使用它？\n怎么使用？\n谁在用？\n尝试一下\n\n\n本文来自于网络，仅用作测试\n正文\n1. Markdown是什么？\nMarkdown是一种轻量级标记语言，它以纯文本形式(易读、易写、易更改)编写文档，并最终以HTML格式发布。\nMarkdown也可以理解为将以MARKDOWN语法编写的语言转换成HTML内容的工具。\n2. 谁创造了它？\n它由Aaron Swartz和John Gruber共同设计，Aaron Swartz就是那位于去年（2013年1月11日）自杀,有着开挂一般人生经历的程序员。维基百科对他的介绍是：软件工程师、作家、政治组织者、互联网活动家、维基百科人。\n他有着足以让你跪拜的人生经历：\n+ 14岁参与RSS 1.0规格标准的制订。\n+ 2004年入读斯坦福，之后退学。\n+ 2005年创建Infogami，之后与Reddit合并成为其合伙人。\n+ 2010年创立求进会（Demand Progress），积极参与禁止网络盗版法案（SOPA）活动，最终该提案被撤回。\n+ 2011年7月19日，因被控从MIT和JSTOR下载480万篇学术论文并以免费形式上传于网络被捕。\n+ 2013年1月自杀身亡。\n\nAaron Swartz\n\n天才都有早逝的归途。\n3. 为什么要使用它？\n\n它是易读（看起来舒服）、易写（语法简单）、易更改纯文本。处处体现着极简主义的影子。\n兼容HTML，可以转换为HTML格式发布。\n跨平台使用。\n越来越多的网站支持Markdown。\n更方便清晰地组织你的电子邮件。（Markdown-here, Airmail）\n摆脱Word（我不是认真的）。\n\n4. 怎么使用？\n如果不算扩展，Markdown的语法绝对简单到让你爱不释手。\nMarkdown语法主要分为如下几大部分： 标题，段落，区块引用，代码区块，强调，列表，分割线，链接，图片，反斜杠 \\，符号'`'。\n4.1 标题\n两种形式：\n1）使用=和-标记一级和二级标题。 &gt; 一级标题\n&gt; =========\n&gt; 二级标题\n&gt; ---------\n效果： &gt; 一级标题\n&gt; =========\n&gt; 二级标题 &gt; ---------\n2）使用#，可表示1-6级标题。 &gt; # 一级标题\n&gt; ## 二级标题\n&gt; ### 三级标题\n&gt; #### 四级标题\n&gt; ##### 五级标题\n&gt; ###### 六级标题\n效果： &gt; # 一级标题\n&gt; ## 二级标题\n&gt; ### 三级标题\n&gt; #### 四级标题\n&gt; ##### 五级标题\n&gt; ###### 六级标题\n4.2 段落\n段落的前后要有空行，所谓的空行是指没有文字内容。若想在段内强制换行的方式是使用两个以上空格加上回车（引用中换行省略回车）。\n4.3 区块引用\n在段落的每行或者只在第一行使用符号&gt;,还可使用多个嵌套引用，如： &gt; &gt; 区块引用\n&gt; &gt;&gt; 嵌套引用\n效果： &gt; 区块引用\n&gt;&gt; 嵌套引用\n4.4 代码区块\n代码区块的建立是在每行加上4个空格或者一个制表符（如同写代码一样）。如\n普通段落：\nvoid main()\n{\nprintf(\"Hello, Markdown.\");\n}\n代码区块：\nvoid main()\n{\n    printf(\"Hello, Markdown.\");\n}\n注意:需要和普通段落之间存在空行。\n4.5 强调\n在强调内容两侧分别加上*或者_，如： &gt; *斜体*，_斜体_\n&gt; **粗体**，__粗体__\n效果： &gt; 斜体，斜体\n&gt; 粗体，粗体\n4.6 列表\n使用·、+、或-标记无序列表，如： &gt; -（+*） 第一项 &gt; -（+*） 第二项 &gt; - （+*）第三项\n注意：标记后面最少有一个_空格_或_制表符_。若不在引用区块中，必须和前方段落之间存在空行。\n效果： &gt; + 第一项 &gt; + 第二项 &gt; + 第三项\n有序列表的标记方式是将上述的符号换成数字,并辅以.，如： &gt; 1 . 第一项\n&gt; 2 . 第二项\n&gt; 3 . 第三项\n效果： &gt; 1. 第一项 &gt; 2. 第二项 &gt; 3. 第三项\n4.7 分割线\n分割线最常使用就是三个或以上*，还可以使用-和_。\n4.8 链接\n链接可以由两种形式生成：行内式和参考式。\n行内式： &gt; [younghz的Markdown库](https:://github.com/younghz/Markdown \"Markdown\")。\n效果： &gt; younghz的Markdown库。\n参考式： &gt; [younghz的Markdown库1][1]\n&gt; [younghz的Markdown库2][2]\n&gt; [1]:https:://github.com/younghz/Markdown \"Markdown\"\n&gt; [2]:https:://github.com/younghz/Markdown \"Markdown\"\n效果： &gt; younghz的Markdown库1\n&gt; younghz的Markdown库2\n注意：上述的[1]:https:://github.com/younghz/Markdown \"Markdown\"不出现在区块中。\n4.9 图片\n添加图片的形式和链接相似，只需在链接的基础上前方加一个！。 #### 4.10 反斜杠\\ 相当于反转义作用。使符号成为普通符号。 #### 4.11 符号'' 起到标记作用。如： &gt;\\ctrl+a`\n效果： &gt;ctrl+a\n5. 谁在用？\nMarkdown的使用者： + GitHub + 简书 + Stack Overflow + Apollo + Moodle + Reddit + 等等\n6. 尝试一下\n\nChrome下的插件诸如stackedit与markdown-here等非常方便，也不用担心平台受限。\n在线的dillinger.io评价也不错\n\nWindowns下的MarkdownPad也用过，不过免费版的体验不是很好。\n\nMac下的Mou是国人贡献的，口碑很好。\nLinux下的ReText不错。\n\n当然，最终境界永远都是笔下是语法，心中格式化 :)。\n\n注意：不同的Markdown解释器或工具对相应语法（扩展语法）的解释效果不尽相同，具体可参见工具的使用说明。 虽然有人想出面搞一个所谓的标准化的Markdown，[没想到还惹怒了健在的创始人John Gruber] (http://blog.codinghorror.com/standard-markdown-is-now-common-markdown/ )。 **** 以上基本是所有traditonal markdown的语法。\n其它：\n列表的使用(非traditonal markdown)：\n用|表示表格纵向边界，表头和表内容用-隔开，并可用:进行对齐设置，两边都有:则表示居中，若不加:则默认左对齐。\n\n\n\n代码库\n链接\n\n\n\n\nMarkDown\nhttps://github.com/younghz/Markdown\n\n\nMarkDownCopy\nhttps://github.com/younghz/Markdown\n\n\n\n关于其它扩展语法可参见具体工具的使用说明。\n","categories":["Test"],"tags":["Test"]}]